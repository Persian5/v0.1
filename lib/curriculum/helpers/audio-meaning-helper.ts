import { AudioMeaningStep, LexemeRef } from "../../types";
import { GrammarService } from "../../services/grammar-service";

/**
 * Internal helper function to generate audio-meaning steps
 * 
 * PHASE 4.1: Now supports LexemeRef (base vocab or grammar forms)
 * 
 * Audio-meaning steps test vocabulary comprehension by playing audio
 * and asking the user to select the correct English meaning.
 * 
 * Distractors are auto-generated by WordBankService when
 * FLAGS.USE_LEARNED_VOCAB_IN_AUDIO_MEANING is enabled (current default).
 * 
 * IMPORTANT: Does NOT resolve LexemeRef during curriculum initialization to avoid
 * circular dependencies. Resolution happens at runtime in the UI component.
 * 
 * @param ref - Lexeme reference (string vocab ID or GrammarRef for grammar forms)
 * @param points - Points for the audio-meaning exercise (default: 2)
 * @param autoPlay - Whether to auto-play audio on load (default: undefined, component decides)
 * @returns AudioMeaningStep with raw LexemeRef stored in data
 * 
 * Examples:
 *   audioMeaningHelper("salam") → tests "salam" (base vocab)
 *   audioMeaningHelper({ kind: "suffix", baseId: "khoob", suffixId: "am" }) → tests "khoobam" (grammar form)
 */
export function audioMeaningHelper(
  ref: LexemeRef,
  points: number = 2,
  autoPlay?: boolean
): AudioMeaningStep {
  // Store the raw LexemeRef - resolution happens at runtime in UI
  // For backward compatibility with string refs:
  const vocabularyId = typeof ref === 'string' ? ref : ref.baseId;
  
  return {
    type: "audio-meaning",
    points,
    data: {
      vocabularyId,                    // Base vocab for tracking (backward compat)
      lexemeRef: ref,                  // NEW: Store raw LexemeRef for runtime resolution
      distractors: [],                 // Empty - WordBankService auto-generates when flag is ON
      autoPlay
    }
  };
}
